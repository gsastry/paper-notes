

# Notes #:

## Key idea: 
A single learning algorithm accounts for the structure of the sensory neurons in different
sensory modalities

- This is a like a "constructive" evidence of the "one learning algorithm" hypothesis

## Summary notes:
- Their results also show that the prior of data encoded in the genome is small - a lot of learning
happens during development
- In the neuroscience lingo, "receptive field" is the part of input data that activates neurons
- They use autoencoders, RBMs, K-means, and sparse coding as their algorithms

### Some implementation details:
- 60000 models (!)
- protected against overfitting in various ways: crossvalidation etc
- Don't really care about the *performance* of models, but rather looking to test the 
one learning algorithm hypothesis


### Environmental learning
- Replicated Dayan's etc goggle rearing experiment with their algos... found the same thing again!
